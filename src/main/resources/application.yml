server:
  port: 8080

spring:
  application:
    name: z-rag
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 100MB
      enabled: true
  web:
    resources:
      static-locations: classpath:/static/
      cache:
        period: 3600

# 模型配置
models:
  # OpenAI配置（需要翻墙）
  openai:
    api:
      key: ${OPENAI_API_KEY:}
    base:
      url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
    model: ${OPENAI_MODEL:gpt-3.5-turbo}
    embedding:
      model: ${OPENAI_EMBEDDING_MODEL:text-embedding-ada-002}
  
  # 千问模型配置（国内可用）
  qwen:
    api:
      key: ${QWEN_API_KEY:}  # 从VM options或环境变量获取
    base:
      url: ${QWEN_BASE_URL:https://dashscope.aliyuncs.com/compatible-mode/v1}
    model: ${QWEN_MODEL:qwen-plus}
    embedding:
      model: ${QWEN_EMBEDDING_MODEL:text-embedding-v3}
  
  # Ollama本地模型配置
  ollama:
    base:
      url: ${OLLAMA_BASE_URL:http://localhost:11434}
    model: ${OLLAMA_MODEL:qwen2.5:7b}
    embedding:
      model: ${OLLAMA_EMBEDDING_MODEL:nomic-embed-text}

# 重排模型配置
rerank:
  # 千问重排模型
  qwen:
    api:
      key: ${QWEN_API_KEY:} # 从VM options或环境变量获取
    base:
      url: ${QWEN_RERANK_BASE_URL:https://dashscope.aliyuncs.com/api/v1/services/rerank/text-rerank/text-rerank}
    model: ${QWEN_RERANK_MODEL:gte-rerank-v2}
  
  # OpenAI重排模型
  openai:
    api:
      key: ${OPENAI_API_KEY:}
    base:
      url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
    model: ${OPENAI_RERANK_MODEL:text-embedding-3-large}
  
  # Ollama重排模型
  ollama:
    base:
      url: ${OLLAMA_BASE_URL:http://localhost:11434}
    model: ${OLLAMA_RERANK_MODEL:qwen2.5:7b}

# MinIO对象存储配置
minio:
  endpoint: ${MINIO_ENDPOINT:} # 从VM options或环境变量获取
  access-key: ${MINIO_ACCESS_KEY:} # 从VM options或环境变量获取
  secret-key: ${MINIO_SECRET_KEY:} # 从VM options或环境变量获取
  bucket-name: ${MINIO_BUCKET_NAME:} # 从VM options或环境变量获取
  auto-create-bucket: true

# Weaviate向量数据库配置
weaviate:
  host: ${WEAVIATE_HOST:localhost}
  port: ${WEAVIATE_PORT:8080}
  scheme: ${WEAVIATE_SCHEME:http}
  class-name: ${WEAVIATE_CLASS_NAME:ZRAGDocument}
  vector-dimension: ${WEAVIATE_VECTOR_DIMENSION:384}  # AllMiniLmL6V2的向量维度
  # 认证配置（选择其中一种）
  api-key: ${WEAVIATE_API_KEY:}
  username: ${WEAVIATE_USERNAME:}
  password: ${WEAVIATE_PASSWORD:}
  access-token: ${WEAVIATE_ACCESS_TOKEN:}

# Milvus向量数据库配置
milvus:
  uri: ${MILVUS_URI:} #从VM options或环境变量获取
  database: ${MILVUS_DATABASE:zrag} #从VM options或环境变量获取
  collection: ${MILVUS_COLLECTION:km} #从VM options或环境变量获取
  # 认证配置
  token: ${MILVUS_TOKEN:}  # 从VM options或环境变量获取
  # 连接配置
  connect-timeout: ${MILVUS_CONNECT_TIMEOUT:10000}
  idle-timeout: ${MILVUS_IDLE_TIMEOUT:60000}
  # 向量配置
  vector-dimension: ${MILVUS_VECTOR_DIMENSION:1024}  # 千问 text-embedding-v3的向量维度
  index-type: ${MILVUS_INDEX_TYPE:IVF_FLAT}
  metric-type: ${MILVUS_METRIC_TYPE:COSINE}

# 向量存储配置
vector-store:
  type: ${VECTOR_STORE_TYPE:milvus}  # 可选: milvus, weaviate, memory

# 文件存储配置
storage:
  type: ${STORAGE_TYPE:minio}  # 可选: minio, local, memory
  local:
    path: ${LOCAL_STORAGE_PATH:./storage}
  minio:
    bucket: ${MINIO_BUCKET_NAME:zrag-documents}
    prefix: ${MINIO_PREFIX:documents/}

# 默认使用的模型提供商
default:
  provider: ${DEFAULT_PROVIDER:qwen}  # 可选: openai, qwen, ollama
  rerank:
    provider: ${DEFAULT_RERANK_PROVIDER:qwen}  # 可选: openai, qwen, ollama

# Apache Tika文档解析配置
tika:
  enabled: ${TIKA_ENABLED:true}  # 是否启用Tika解析
  max-text-length: ${TIKA_MAX_TEXT_LENGTH:100000}  # 最大文本长度
  timeout: ${TIKA_TIMEOUT:30000}  # 解析超时时间（毫秒）

# 日志配置
logging:
  level:
    com.unionhole.zrag: INFO
    dev.langchain4j: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
